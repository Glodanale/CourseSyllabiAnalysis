{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Target Fill Values\n",
    "\n",
    "This file processes the syllabi text through tf/idf vectorization to perform clustering on the documents.  Some documents do not have values for the target variable \"RATING\".  The documents are clustered to find the k value with the highest silhouette score while having at least one document with an assigned target value for every cluster.  If a document does not have a target value, it is assigned the value of the average of the assigned values in its cluster.\n",
    "\n",
    "\n",
    "### Input:  InstructorRatingsCSV.csv, TextFiles_Combo folder\n",
    "### Output: targeFillDocs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load data and preprocess\n",
    "csv_path = \"InstructorRatingsCSV.csv\"\n",
    "folder_path = \"TextFiles_Combo\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical features\n",
    "label_encoders = {}\n",
    "for col in [\"COURSENAME\", \"INSTRUCTOR\", \"LEVEL\", \"LOCATION\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text documents\n",
    "documents = []\n",
    "for file_name in df[\"ID\"]:\n",
    "    with open(os.path.join(folder_path, file_name + \".txt\"), 'r') as file:\n",
    "        documents.append(file.read())\n",
    "\n",
    "df[\"Document\"] = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 60985)\t0.038234915894566554\n",
      "  (0, 18766)\t0.1360222878319367\n",
      "  (0, 64969)\t0.011342809294227338\n",
      "  (0, 22382)\t0.012443112229009368\n",
      "  (0, 17236)\t0.01675614143591706\n",
      "  (0, 15882)\t0.016829831729980534\n",
      "  (0, 12748)\t0.0150782292387542\n",
      "  (0, 65998)\t0.05428162525951512\n",
      "  (0, 25234)\t0.0028794757230244396\n",
      "  (0, 66101)\t0.0028794757230244396\n",
      "  (0, 62341)\t0.00558538047863902\n",
      "  (0, 69041)\t0.012365662530176064\n",
      "  (0, 20217)\t0.06403123334178575\n",
      "  (0, 988)\t0.07140368625866389\n",
      "  (0, 1067)\t0.16188304119952796\n",
      "  (0, 70066)\t0.028357023235568345\n",
      "  (0, 35925)\t0.0433415553578456\n",
      "  (0, 59748)\t0.02200330752405097\n",
      "  (0, 29739)\t0.0029240378746932874\n",
      "  (0, 73195)\t0.007944373329833469\n",
      "  (0, 2416)\t0.0029694177259913523\n",
      "  (0, 39908)\t0.04564995092185721\n",
      "  (0, 59288)\t0.0315398268522168\n",
      "  (0, 93)\t0.03746930039760649\n",
      "  (0, 160)\t0.01261593074088672\n",
      "  :\t:\n",
      "  (64, 8797)\t0.018784038677380557\n",
      "  (64, 1606)\t0.018784038677380557\n",
      "  (64, 26305)\t0.018784038677380557\n",
      "  (64, 27694)\t0.018784038677380557\n",
      "  (64, 3130)\t0.018784038677380557\n",
      "  (64, 60633)\t0.018784038677380557\n",
      "  (64, 26309)\t0.018784038677380557\n",
      "  (64, 27743)\t0.018784038677380557\n",
      "  (64, 62960)\t0.018784038677380557\n",
      "  (64, 30892)\t0.018784038677380557\n",
      "  (64, 40768)\t0.018784038677380557\n",
      "  (64, 20840)\t0.018784038677380557\n",
      "  (64, 37422)\t0.018784038677380557\n",
      "  (64, 64748)\t0.018784038677380557\n",
      "  (64, 36571)\t0.018784038677380557\n",
      "  (64, 58453)\t0.018784038677380557\n",
      "  (64, 48657)\t0.018784038677380557\n",
      "  (64, 30904)\t0.018784038677380557\n",
      "  (64, 64746)\t0.018784038677380557\n",
      "  (64, 26182)\t0.018784038677380557\n",
      "  (64, 48667)\t0.018784038677380557\n",
      "  (64, 69438)\t0.018784038677380557\n",
      "  (64, 62085)\t0.018784038677380557\n",
      "  (64, 64694)\t0.018784038677380557\n",
      "  (64, 21767)\t0.018784038677380557\n"
     ]
    }
   ],
   "source": [
    "# Step 2: TF-IDF vectorization and top n-gram extraction\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Document\"])\n",
    "\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ID  COURSENAME  INSTRUCTOR  LEVEL  LOCATION  \\\n",
      "0          CSCI-1100-003-Haas          42           9      1         0   \n",
      "1          CSCI-1100-901-Haas          42           9      1         1   \n",
      "2       CSCI-1120-901-Hendrix           0          11      1         1   \n",
      "3    CSCI-1200-001-Desjardins           2           5      1         0   \n",
      "4        CSCI-1210-001-Ramsey          16          16      1         0   \n",
      "..                        ...         ...         ...    ...       ...   \n",
      "60  CSCI-5607-001-Bajracharya          19           0      0         1   \n",
      "61    CSCI-5757-001-Battleson          20           1      0         0   \n",
      "62      CSCI-5927-201-Rezwana          18          17      0         0   \n",
      "63  CSCI-5957-002-Bajracharya          39           0      0         0   \n",
      "64      CSCI-5989-001-Bennett          22           2      0         1   \n",
      "\n",
      "    RATING                                           Document  Cluster  \n",
      "0     40.0  On-site Course Syllabus DEPARTMENT of COMPUTIN...        2  \n",
      "1     45.0  Online Asynchronous Course Syllabus DEPARTMENT...        2  \n",
      "2     30.0  EAST TENNESSEE STATE UNIVERSITY CSCI‐1120 — Ad...        1  \n",
      "3      NaN  CSCI 1200 Adventures in Computing Proposed: Co...        2  \n",
      "4      NaN  Credit hours: 3 Instructor Jack Ramsey Email: ...        2  \n",
      "..     ...                                                ...      ...  \n",
      "60     NaN  EAST TENNESSEE STATE UNIVERSITY CSCI 4607-001 ...        4  \n",
      "61     NaN  DEPARTMENT of COMPUTING College of business & ...        1  \n",
      "62    85.0  CSCI 4927/5927 - HUMAN COMPUTER INTERACTION CO...        1  \n",
      "63     NaN  EAST TENNESSEE STATE UNIVERSITY CSCI 4957 — Sp...        4  \n",
      "64     NaN  COLLEGE of BUSINESS & TECHNOLOGY EAST TENNESSE...        2  \n",
      "\n",
      "[65 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: K-Means clustering\n",
    "silhouette_scores = []\n",
    "k_values = range(2, 11)\n",
    "\n",
    "# Ensure every cluster has at least one labeled document\n",
    "def ensure_clusters_have_labels(cluster_labels, df):\n",
    "    cluster_valid = True\n",
    "    for cluster in set(cluster_labels):\n",
    "        if df[(df['Cluster'] == cluster) & (df['RATING'].notna())].empty:\n",
    "            cluster_valid = False\n",
    "            break\n",
    "    return cluster_valid\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "    df['Cluster'] = cluster_labels\n",
    "    \n",
    "    # Check if all clusters have at least one labeled document\n",
    "    if ensure_clusters_have_labels(cluster_labels, df):\n",
    "        score = silhouette_score(tfidf_matrix, cluster_labels)\n",
    "        silhouette_scores.append(score)\n",
    "    else:\n",
    "        silhouette_scores.append(-1)  # Penalize clustering results that fail this condition\n",
    "\n",
    "# Find optimal k ensuring valid clustering\n",
    "optimal_k = k_values[np.argmax(silhouette_scores)]\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Final check and reassignment for unlabeled clusters\n",
    "while not ensure_clusters_have_labels(cluster_labels, df):\n",
    "    print(\"Recomputing clusters to ensure each cluster has at least one labeled document.\")\n",
    "    df = df.sample(frac=1, random_state=42)  # Shuffle the DataFrame\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "    df['Cluster'] = cluster_labels\n",
    "\n",
    "print(optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute averages for missing ratings\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_indices = df[df['Cluster'] == cluster].index\n",
    "    cluster_mean = df.loc[cluster_indices, 'RATING'].dropna().mean()\n",
    "    df.loc[cluster_indices, 'RATING'] = df.loc[cluster_indices, 'RATING'].fillna(cluster_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ID  COURSENAME  INSTRUCTOR  LEVEL  LOCATION  \\\n",
      "0          CSCI-1100-003-Haas          42           9      1         0   \n",
      "1          CSCI-1100-901-Haas          42           9      1         1   \n",
      "2       CSCI-1120-901-Hendrix           0          11      1         1   \n",
      "3    CSCI-1200-001-Desjardins           2           5      1         0   \n",
      "4        CSCI-1210-001-Ramsey          16          16      1         0   \n",
      "..                        ...         ...         ...    ...       ...   \n",
      "60  CSCI-5607-001-Bajracharya          19           0      0         1   \n",
      "61    CSCI-5757-001-Battleson          20           1      0         0   \n",
      "62      CSCI-5927-201-Rezwana          18          17      0         0   \n",
      "63  CSCI-5957-002-Bajracharya          39           0      0         0   \n",
      "64      CSCI-5989-001-Bennett          22           2      0         1   \n",
      "\n",
      "       RATING                                           Document  Cluster  \n",
      "0   40.000000  On-site Course Syllabus DEPARTMENT of COMPUTIN...        2  \n",
      "1   45.000000  Online Asynchronous Course Syllabus DEPARTMENT...        2  \n",
      "2   30.000000  EAST TENNESSEE STATE UNIVERSITY CSCI‐1120 — Ad...        1  \n",
      "3   43.750000  CSCI 1200 Adventures in Computing Proposed: Co...        2  \n",
      "4   43.750000  Credit hours: 3 Instructor Jack Ramsey Email: ...        2  \n",
      "..        ...                                                ...      ...  \n",
      "60  15.000000  EAST TENNESSEE STATE UNIVERSITY CSCI 4607-001 ...        4  \n",
      "61  66.666667  DEPARTMENT of COMPUTING College of business & ...        1  \n",
      "62  85.000000  CSCI 4927/5927 - HUMAN COMPUTER INTERACTION CO...        1  \n",
      "63  15.000000  EAST TENNESSEE STATE UNIVERSITY CSCI 4957 — Sp...        4  \n",
      "64  43.750000  COLLEGE of BUSINESS & TECHNOLOGY EAST TENNESSE...        2  \n",
      "\n",
      "[65 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Document\"])\n",
    "\n",
    "df.to_csv(\"targetFillDocs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
